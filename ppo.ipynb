{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f531819",
   "metadata": {},
   "source": [
    "# PPO Training with LoRA-Tuned LLM for Texas Hold'em Poker\n",
    "\n",
    "This notebook contains the complete implementation and testing of PPO (Proximal Policy Optimization) training for a poker-playing agent using LoRA-tuned language models.\n",
    "\n",
    "## Content Overview:\n",
    "1. **Poker Game Testing** - Basic poker game functionality\n",
    "2. **Hand Evaluation** - Card evaluation and ranking\n",
    "3. **Game State Management** - Player states and actions\n",
    "4. **Multi-player Games** - Testing 2-player and 6-player scenarios\n",
    "5. **PPO Configuration** - Reward calculation and training setup\n",
    "6. **Model Loading** - Hugging Face model integration\n",
    "7. **Agent Testing** - Random agents and LLM agents\n",
    "8. **Training Pipeline** - Complete PPO training workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e028a3",
   "metadata": {},
   "source": [
    "## 1. Basic Poker Game Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb41290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eight Of Club, Ace Of Spade, Eight Of Heart, Nine Of Diamond, Nine Of Spade]\n"
     ]
    }
   ],
   "source": [
    "from poker_game import Deck, Card\n",
    "\n",
    "deck = Deck()  # Reproducible shuffling\n",
    "cards = deck.deal(5)  # Deal 5 cards\n",
    "print(cards)  # [Ah, Kd, Qs, Jc, Ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f680853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two Pair\n"
     ]
    }
   ],
   "source": [
    "from poker_game import HandEvaluator, Card\n",
    "\n",
    "cards = [Card.from_string(s) for s in ['Ah', 'Ad', 'Kh', 'Kd', 'Qs']]\n",
    "hand_rank, tiebreakers = HandEvaluator.evaluate_hand(cards)\n",
    "description = HandEvaluator.get_hand_description(cards)\n",
    "print(description)  # \"Two Pair\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a6abc",
   "metadata": {},
   "source": [
    "## 2. Game State and Player Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "199ef70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0\n"
     ]
    }
   ],
   "source": [
    "from poker_game import GameState, PlayerState, Action\n",
    "\n",
    "player = PlayerState(player_id=0, stack=100.0)\n",
    "player.bet(10.0)  # Place a bet\n",
    "print(player.stack)  # 90.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70afa589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hand #1 - PREFLOP\n",
      "Board: (no cards yet)\n",
      "Pot: $8.0\n",
      "\n",
      "Players:\n",
      "  BB (P0): $99.0 (ACTIVE) [Nine Of Diamond Ace Of Diamond]\n",
      "  SB (P1): $93.0 (ACTIVE) [Two Of Heart Seven Of Diamond]\n",
      "\n",
      "Action on: BB (P0)\n",
      "Current bet: $7.0\n"
     ]
    }
   ],
   "source": [
    "from poker_game import PokerGame, Action\n",
    "\n",
    "# Create a game\n",
    "game = PokerGame(num_players=2, starting_stack=100.0, small_blind=0.5, big_blind=1.0)\n",
    "\n",
    "# Start a hand\n",
    "state = game.reset()\n",
    "\n",
    "# Get valid actions for current player\n",
    "player = state.current_player()\n",
    "valid_actions = state.get_valid_actions(player)\n",
    "\n",
    "# Execute an action\n",
    "new_state, hand_complete, result = game.step(Action.RAISE, amount=6.0)\n",
    "\n",
    "# Print game state\n",
    "print(game.get_game_state_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f496bd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current player: 0 (BB)\n",
      "Current player index: 0\n",
      "It's someone's turn - action required\n",
      "Valid actions for current player: ['fold', 'call', 'raise']\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Use state.current_player()\n",
    "current_player = state.current_player()\n",
    "print(f\"Current player: {current_player.player_id} ({current_player.position})\")\n",
    "\n",
    "# Method 2: Use state.current_player_idx\n",
    "print(f\"Current player index: {state.current_player_idx}\")\n",
    "\n",
    "# Method 3: Check if betting round is complete\n",
    "if not state.is_betting_round_complete():\n",
    "    print(\"It's someone's turn - action required\")\n",
    "else:\n",
    "    print(\"Betting round is complete - no action needed\")\n",
    "\n",
    "# Method 4: Get valid actions for current player\n",
    "valid_actions = state.get_valid_actions(current_player)\n",
    "print(f\"Valid actions for current player: {[a.value for a in valid_actions]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e98ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current betting round: BettingRound.PREFLOP\n",
      "Action history: [{'player_id': 1, 'action': 'bet', 'amount': 0.5, 'betting_round': 'preflop', 'pot_after': 0.5, 'is_blind': True}, {'player_id': 0, 'action': 'bet', 'amount': 1.0, 'betting_round': 'preflop', 'pot_after': 1.5, 'is_blind': True}, {'player_id': 1, 'action': 'raise', 'amount': 6.0, 'betting_round': 'preflop', 'pot_after': 8.0, 'is_blind': False}]\n",
      "\n",
      "LLM Prompt:\n",
      "You are a specialist in playing heads-up No Limit Texas Holdem. The following will be a game scenario and you need to make the optimal decision.\n",
      "\n",
      "Here is a game summary:\n",
      "\n",
      "The small blind is 0.5 chips and the big blind is 1.0 chips. Everyone started with 100.0 chips.\n",
      "The player positions involved in this game are SB, BB.\n",
      "In this hand, your position is BB, and your holding is [Nine Of Diamond and Ace Of Diamond].\n",
      "Before the flop, SB raise 6.0 chips. Assume that all other players that is not mentioned folded.\n",
      "\n",
      "Now it is your turn to make a move.\n",
      "To remind you, the current pot size is 8.0 chips, and your holding is [Nine Of Diamond and Ace Of Diamond].\n",
      "\n",
      "Decide on an action based on the strength of your hand on this board, your position, and actions before you. Do not explain your answer.\n",
      "Your optimal action is:\n"
     ]
    }
   ],
   "source": [
    "# Test LLM prompt generation\n",
    "print(f\"Current betting round: {state.betting_round}\")\n",
    "print(f\"Action history: {state.action_history}\")\n",
    "print()\n",
    "\n",
    "prompt = state.get_llm_prompt(player_perspective=0)\n",
    "print(\"LLM Prompt:\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f580d0",
   "metadata": {},
   "source": [
    "## 3. Multi-Player Game Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3989446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6-handed poker:\n",
      "Button position: 1\n",
      "Player positions:\n",
      "  Player 0: CO\n",
      "  Player 1: BTN\n",
      "  Player 2: SB\n",
      "  Player 3: BB\n",
      "  Player 4: UTG\n",
      "  Player 5: HJ\n",
      "Action history:\n",
      "  bet by SB\n",
      "  bet by BB\n"
     ]
    }
   ],
   "source": [
    "# Test 6-player game\n",
    "from poker_game import PokerGame\n",
    "\n",
    "# Create a 6-player game\n",
    "game6 = PokerGame(num_players=6, starting_stack=100.0, small_blind=0.5, big_blind=1.0)\n",
    "state6 = game6.reset()\n",
    "\n",
    "print('6-handed poker:')\n",
    "print(f'Button position: {state6.button_position}')\n",
    "print('Player positions:')\n",
    "for i, player in enumerate(game6.players):\n",
    "    print(f'  Player {i}: {player.position}')\n",
    "print('Action history:')\n",
    "for action in state6.action_history:\n",
    "    player_pos = game6.players[action['player_id']].position\n",
    "    print(f\"  {action['action']} by {player_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "832d0a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct stack check:\n",
      "  Player 0 (CO): $100.0\n",
      "  Player 1 (BTN): $100.0\n",
      "  Player 2 (SB): $99.5\n",
      "  Player 3 (BB): $99.0\n",
      "  Player 4 (UTG): $100.0\n",
      "  Player 5 (HJ): $100.0\n"
     ]
    }
   ],
   "source": [
    "print('Direct stack check:')\n",
    "for i, player in enumerate(game6.players):\n",
    "    print(f'  Player {i} ({player.position}): ${player.stack:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543d2ef8",
   "metadata": {},
   "source": [
    "## 4. PPO Configuration and Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c8b64e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminal reward = 10.0\n",
      "Reward trajectory: [ 0.  0. 10.]\n"
     ]
    }
   ],
   "source": [
    "from ppo.config import PPOConfig\n",
    "from ppo.rewards import RewardCalculator\n",
    "from poker_game.game_state import Action\n",
    "import numpy as np\n",
    "\n",
    "cfg = PPOConfig()\n",
    "rc  = RewardCalculator(big_blind=cfg.big_blind)\n",
    "\n",
    "# Terminal reward: initial 100, ending 110, BB=1 => reward should be 10.0\n",
    "r = rc.calculate_reward(player_id=0, action=Action.CALL, hand_result={},\n",
    "                        initial_stack=100.0, final_stack=110.0, big_blind=cfg.big_blind)\n",
    "print(\"terminal reward =\", r)  # Expected: 10.0\n",
    "\n",
    "# Construct a 3-step trajectory: first two steps 0, last step has terminal reward\n",
    "rewards = np.array([0.0, 0.0, r])\n",
    "print(\"Reward trajectory:\", rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997d490e",
   "metadata": {},
   "source": [
    "## 5. Model Loading and Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7bf102",
   "metadata": {},
   "source": [
    "## 6. Agent Testing and Action Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55e7f3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pot = 1.5 Legal = [<Action.FOLD: 'fold'>, <Action.CALL: 'call'>, <Action.RAISE: 'raise'>]\n",
      "bet_0.50pot -> amount = 0.75\n",
      "legalized: Action.CALL 0.0\n",
      "illegal label fallback -> Action.RAISE 99.5\n"
     ]
    }
   ],
   "source": [
    "# A.1 Set up a minimal poker environment\n",
    "from poker_game.game_logic import PokerGame\n",
    "from poker_game.game_state import Action\n",
    "from ppo.agents import _amount_from_label, _legalize_label\n",
    "\n",
    "env = PokerGame(num_players=2, starting_stack=100.0, small_blind=0.5, big_blind=1.0, seed=42)\n",
    "state = env.reset()\n",
    "actor = state.current_player()                # Current acting player\n",
    "legal = state.get_valid_actions(actor)\n",
    "\n",
    "print(\"Pot =\", state.pot, \"Legal =\", legal)\n",
    "\n",
    "# A.2 Amount conversion (e.g. 0.5 pot bet)\n",
    "amt = _amount_from_label(\"bet_0.50pot\", state, actor)\n",
    "print(\"bet_0.50pot -> amount =\", amt)\n",
    "\n",
    "# A.3 Legalization (in preflop first round usually allows BET; if not allowed, downgrade to CHECK/CALL/FOLD)\n",
    "action, final_amt = _legalize_label(\"bet_0.50pot\", legal, state, actor)\n",
    "print(\"legalized:\", action, final_amt)\n",
    "\n",
    "# A.4 An \"obviously illegal\" label (like raise_allin may not be legal in most early states) → see if downgrade works\n",
    "action2, amt2 = _legalize_label(\"raise_allin\", legal, state, actor)\n",
    "print(\"illegal label fallback ->\", action2, amt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2248d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hand over. result: {'winners': [0], 'win_type': 'fold', 'pot': 1.5, 'final_board': []}\n",
      "Final stacks: [100.5, 99.5]\n"
     ]
    }
   ],
   "source": [
    "from ppo.agents import RandomAgent\n",
    "from poker_game.game_logic import PokerGame\n",
    "\n",
    "env = PokerGame(num_players=2, starting_stack=100.0, small_blind=0.5, big_blind=1.0, seed=7)\n",
    "state = env.reset()\n",
    "\n",
    "agent0 = RandomAgent(0, seed=1)\n",
    "agent1 = RandomAgent(1, seed=2)\n",
    "\n",
    "steps = 0\n",
    "while True:\n",
    "    cur = state.current_player()\n",
    "    legal = state.get_valid_actions(cur)\n",
    "    a, amt, info = (agent0 if cur.player_id==0 else agent1).act(state, legal)\n",
    "    state, done, result = env.step(a, amt)\n",
    "    steps += 1\n",
    "    if done or steps > 50:\n",
    "        print(\"Hand over. result:\", result)\n",
    "        break\n",
    "\n",
    "print(\"Final stacks:\", [p.stack for p in env.players])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d373a",
   "metadata": {},
   "source": [
    "## 7. PPO Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1b59607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 completed\n",
      "Episode 2 completed\n",
      "Episode 3 completed\n",
      "Episode 4 completed\n",
      "Episode 5 completed\n",
      "Training setup test completed!\n"
     ]
    }
   ],
   "source": [
    "from ppo.config import PPOConfig\n",
    "from ppo.rewards import RewardCalculator\n",
    "from ppo.ppo_trainer import PPOTrainer\n",
    "from ppo.agents import RandomAgent\n",
    "\n",
    "cfg = PPOConfig()\n",
    "cfg.num_episodes = 5\n",
    "cfg.num_players  = 2  # Must match the number of agents\n",
    "cfg.save_frequency = 0\n",
    "\n",
    "rc = RewardCalculator(cfg.big_blind)\n",
    "trainer = PPOTrainer(cfg, rc)\n",
    "\n",
    "agents = [RandomAgent(0, seed=1), RandomAgent(1, seed=2)]\n",
    "env = trainer._init_env()  # Initialize environment\n",
    "\n",
    "for ep in range(1, cfg.num_episodes + 1):\n",
    "    trainer.cfg.seed = 42 + ep   # Set seed\n",
    "    log = trainer.play_one_episode(env=env, agents=agents)  # Play with agents\n",
    "    print(f\"Episode {ep} completed\")\n",
    "    \n",
    "print(\"Training setup test completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24aad11",
   "metadata": {},
   "source": [
    "## 8. LLM Agent Testing (Mock Setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ded9004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock LLM agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "import types, math, torch\n",
    "from ppo.agents import LLMAgent, DISCRETE_ACTIONS\n",
    "from poker_game.game_logic import PokerGame\n",
    "\n",
    "# 1) Create an LLMAgent, but we won't actually use its model/tokenizer (avoiding loading large models)\n",
    "agent = LLMAgent.__new__(LLMAgent)  # Bypass __init__\n",
    "agent.player_id = 0\n",
    "agent.max_seq_len = 512\n",
    "agent.temperature = 0.0           # Set to 0: greedy, for easier assertion\n",
    "agent.top_p = 0.9\n",
    "agent.use_scoring = True\n",
    "agent._controller = None\n",
    "agent._adapter_name = None\n",
    "\n",
    "# Mock tokenizer/model minimal fields needed (won't actually be used)\n",
    "agent.tokenizer = types.SimpleNamespace(pad_token_id=0, eos_token_id=0)\n",
    "class _FakeParam: \n",
    "    def device(self): return torch.device(\"cpu\")\n",
    "class _FakeModel:\n",
    "    def __init__(self): self._p = torch.nn.Parameter(torch.zeros(1))\n",
    "    def parameters(self): return [self._p]\n",
    "    def to(self, device): return self\n",
    "\n",
    "agent.model = _FakeModel()\n",
    "print(\"Mock LLM agent created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b009bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. keys: ['steps', 'stacks_init', 'stacks_final', 'result', 'terminal_rewards']\n",
      "steps = 1 stacks: [100.0, 100.0] → [101.0, 99.0]\n",
      "result = {'winners': [0], 'win_type': 'showdown', 'pot': 2.0, 'pot_share': 2.0, 'winning_hand': 'Two Pair', 'final_board': ['Ace Of Club', 'Five Of Diamond', 'Two Of Spade', 'King Of Heart', 'King Of Diamond'], 'all_hands': [(0, 'Two Pair'), (1, 'Two Pair')]}\n"
     ]
    }
   ],
   "source": [
    "# --- Smoke test: PPOTrainer viability check (without loading LLM) ---\n",
    "from ppo.config import PPOConfig\n",
    "from ppo.rewards import RewardCalculator\n",
    "from ppo.ppo_trainer import PPOTrainer\n",
    "from ppo.agents import RandomAgent\n",
    "\n",
    "# 1) Small config + reward calculator + Trainer\n",
    "cfg = PPOConfig()\n",
    "cfg.num_episodes = 5\n",
    "cfg.num_players = 2\n",
    "cfg.steps_per_episode = 50\n",
    "cfg.save_frequency = 0\n",
    "rc = RewardCalculator(big_blind=cfg.big_blind)\n",
    "trainer = PPOTrainer(cfg, reward_calculator=rc)\n",
    "\n",
    "# 2) Two random agents, avoiding loading large models\n",
    "agents = [RandomAgent(0, seed=1), RandomAgent(1, seed=2)]\n",
    "\n",
    "# 3) Test episode execution\n",
    "log = trainer.play_one_episode(agents=agents)\n",
    "print(\"OK. keys:\", list(log.keys()))\n",
    "print(\"steps =\", log[\"steps\"], \"stacks:\", log[\"stacks_init\"], \"→\", log[\"stacks_final\"])\n",
    "print(\"result =\", log.get(\"result\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d069ecc",
   "metadata": {},
   "source": [
    "## 9. Final Model Integration Test\n",
    "\n",
    "⚠️ **Note**: This cell contains the code that previously caused the notebook corruption due to disk space issues. Only run if you have sufficient disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65685dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded successfully. Vocab size: 128256\n"
     ]
    }
   ],
   "source": [
    "# WARNING: This cell caused the original notebook corruption due to disk quota exceeded\n",
    "# Only run if you have sufficient disk space and system resources\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from ppo.config import PPOConfig\n",
    "\n",
    "# Create a config instance\n",
    "C = PPOConfig()\n",
    "\n",
    "# Test tokenizer loading (this should work without loading the full model)\n",
    "try:\n",
    "    tok = AutoTokenizer.from_pretrained(C.base_repo_or_path, trust_remote_code=True)\n",
    "    print(\"Tokenizer loaded successfully. Vocab size:\", len(tok))\n",
    "except Exception as e:\n",
    "    print(f\"Error loading tokenizer: {e}\")\n",
    "    print(\"This is likely due to insufficient disk space or memory issues.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6220",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
