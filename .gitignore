# Python
__pycache__/
*.py[cod]
*.so

# Jupyter
.ipynb_checkpoints

# Environment
.env
.venv
env/
venv/
.conda/

# Logs
logs/
*.log

# Model artifacts (ignore heavy files but keep final LoRA adapter & tokenizer for inference)
poker-lora-model/
models/
# Generic binary ignore
*.safetensors
*.pt
*.bin

# Whitelist the final LoRA adapter and tokenizer files for tracking
!poker-lora-model/Meta-Llama-3-8B/
!poker-lora-model/Meta-Llama-3-8B/adapter_model.safetensors
!poker-lora-model/Meta-Llama-3-8B/adapter_config.json
!poker-lora-model/Meta-Llama-3-8B/tokenizer.json
!poker-lora-model/Meta-Llama-3-8B/tokenizer_config.json
!poker-lora-model/Meta-Llama-3-8B/special_tokens_map.json
!poker-lora-model/Meta-Llama-3-8B/tokenizer.model
!poker-lora-model/Meta-Llama-3-8B/README.md

# HuggingFace caches
/home/hice1/bshu30/.cache/huggingface

# OS files
.DS_Store
*.swp

# Checkpoints and temp
**/checkpoint-*/
**/optimizer.pt
**/scheduler.pt
**/scaler.pt
**/rng_state.pth

# Large files
*.tar.gz
*.tgz

# VSCode
.vscode/
